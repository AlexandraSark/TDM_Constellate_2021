{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZtnwJbt6oJT"
   },
   "source": [
    "By <a href=\"https://nkelber.com\">Nathan Kelber</a> and Ted Lawless <br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.\n",
    "____\n",
    "\n",
    "## Explore the metadata for a JSTOR and/or Portico dataset\n",
    "\n",
    "**Difficulty:** Beginner\n",
    "\n",
    "**Programming Knowledge Required:** \n",
    "This notebook can be run on a JSTOR/Portico non-consumptive JSON Lines (.jsonl) dataset with little to no knowledge of Python. To have a full understanding of the code used in this notebook, we recommend learning:\n",
    "* [Python Basics](https://automatetheboringstuff.com/2e/chapter1/)\n",
    "* [Flow Control](https://automatetheboringstuff.com/2e/chapter2/)\n",
    "* [Functions](https://automatetheboringstuff.com/2e/chapter3/)\n",
    "* [Lists](https://automatetheboringstuff.com/2e/chapter4/)\n",
    "* [Reading and Writing Files](https://automatetheboringstuff.com/2e/chapter9/)\n",
    "\n",
    "A familiarity with Pandas is helpful but not required.\n",
    "\n",
    "**Completion time:** 20 minutes\n",
    "\n",
    "**Data Format:** JSTOR/Portico non-consumptive JSON Lines (.jsonl)\n",
    "\n",
    "**Libraries Used:**\n",
    "* json to convert our dataset from json lines format to python\n",
    "* [Pandas](./key-terms.ipynb#pandas) to help visualize the metadata\n",
    "\n",
    "**Description of methods in this notebook:**\n",
    "This notebook shows how to explore the metadata of your JSTOR and/or Portico dataset using Python. The following processes are described:\n",
    "\n",
    "* Importing your dataset\n",
    "* Discovering the size and contents of your dataset\n",
    "* Turning your dataset into a pandas dataframe\n",
    "* Visualizing the contents of your dataset as a graph with pandas\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9IRRS466oJU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #imports pandas and allows us to call it with the phrase pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `as pd` just lets us use the shorthand `pd` when we want to call pandas instead writing out the entire word `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'shakespeareQuarterly.jsonl' #Replace with your filename and be sure your file is in your datasets folder\n",
    "\n",
    "import json #import the json module\n",
    "all_documents = [] #create an empty new list variable named `all_documents`\n",
    "with open('./datasets/' + fileName) as dataset_file: #temporarily open the file `filename` in the datasets/ folder\n",
    "    for line in dataset_file: #for each line in the dataset file\n",
    "        # Read each line into a Python dictionary.\n",
    "        document = json.loads(line) #create a variable document that contains the line using json.loads to convert the json key/value pairs to a python dictionary\n",
    "        all_documents.append(document) #append a new list item to `all_documents` containing the dictionary we created "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin working with our dataset, we need to convert the JSON lines file written in JavaScript into valid Python. Remember that each line of our JSON lines file represents a single text, whether that is a journal article, book, or something else. We can create a Python list where every item in the list represents a single text. \n",
    "\n",
    "![Structure of the corpus, a list of dictionaries](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CorpusView.png)\n",
    "\n",
    "Each item of our list can then contain a Python dictionary of key/value pairs that allows us to get a value if we supply a key. Our whole corpus is stored in a list variable called `all_documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6687"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine how many texts are in our dataset by using the `len()` function to get the size of `all_documents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Othello's Black Handkerchief\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenDocument = all_documents[0] #define a new dictionary variable `chosenDocument` that is equal to the first item in our `all_documents` list\n",
    "chosenDocument.get('title') #get the corresponding value for the key 'title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose a single document and get metadata for that item. Let's try the first document. (In computer code, 0 is the first item, 1 is the second item, 2 is the third item, etc.) In this case, we use the `.get` method to retrieve the title for our the first item in our list `all_documents[0]`. We can use this method to discover many kinds of metadata in our original file. Here are a few more:\n",
    "* .get('') returns the title\n",
    "* .get('')\n",
    "* .get(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'title' returns Othello's Black Handkerchief\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Othello's Black Handkerchief\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"'title' returns \" + chosenDocument.get('title'))\n",
    "chosenDocument.get('title')\n",
    "chosenDocument.get('title')\n",
    "chosenDocument.get('title')\n",
    "chosenDocument.get('title')\n",
    "chosenDocument.get('title')\n",
    "chosenDocument.get('title')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if a particular item is in our list if we know the stable url using the `in` or `not in` operators. Let's check to see if Shakespearean scholar Theodore B. Leinwand's article \"Shakespeare and the Middling Sort\" is in our dataset. From a JSTOR search, I know that the stable URL for the article is: https://www.jstor.org/stable/2871420 . We can put this stable URL in a string between single quotes and evaluate the phrase with `in dset.items`. If the article is in our dataset, we will receive `true`. If it is not our dataset, we will receive `false`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'http://www.jstor.org/stable/2871420' in dset.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toqiQRaZ6oJd"
   },
   "source": [
    "The document metadata can be retrieved by calling the `get_metadata` method. The metadata is a list of Python dictionaries containing attributes for each document. We create a new list variable `metadata` by using the `get_metadata` method on dset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L39GySgQ6oJe"
   },
   "outputs": [],
   "source": [
    "metadata = dset.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q67bV07z6oJf"
   },
   "source": [
    "Print the contents of **metadata** for the first document in the dataset. The data is displayed as a dictionary of key/value pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUaaExvS6oJg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHkQ1o7P6oJh"
   },
   "source": [
    "We can convert `metadata` to a Pandas dataframe to take advantage of its plotting and manipulation functions. This will help us learn more about what's in our metadata. We define this new dataframe as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWaiiLtC6oJi"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIDbi3SD6oJj"
   },
   "source": [
    "Print the first 5 rows of the dataframe `df` with the `head` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIJ8H0pT6oJk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOkMFJ246oJl"
   },
   "source": [
    "We can find the year range in our pandas dataframe by finding the minimum and maximum of `datePublished`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkhgmqPo6oJm"
   },
   "outputs": [],
   "source": [
    "minYear = df['publicationYear'].min()\n",
    "maxYear = df['publicationYear'].max()\n",
    "\n",
    "print(str(minYear) + ' to ' + str(maxYear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtjvEi9n6oJn"
   },
   "source": [
    "Now let's do some preliminary analysis. Let's say we want to plot the number of documents by decade in the sample set. \n",
    "\n",
    "Since `decade` isn't a value in our dataset, we need to add it to the dataframe. We can do this by defining a new dataframe column `decade`. To translate a year (1925) to a decade (1920), we need to subtract the final digit so it becomes a zero. We can find the value for the final digit in any particular case by using modulo (which provides the remainder of a division). Here's an example using the date 1925."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1925 - (1925 % 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can translate this example to the whole dataframe using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWoq2gMt6oJn"
   },
   "outputs": [],
   "source": [
    "def add_decade(value): \n",
    "    yr = int(value) \n",
    "    decade = yr - ( yr % 10 )\n",
    "    return decade\n",
    "\n",
    "df['decade'] = df['publicationYear'].apply(add_decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H79W5vIw6oJp"
   },
   "source": [
    "To see the new decade column in our data, let's print the first 5 rows of the dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKCjvDna6oJq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lwdgRAf6oJr"
   },
   "source": [
    "Now we can use the built in plotting tools of Pandas to plot the number of documents from each provider by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upxLwnZr6oJs"
   },
   "outputs": [],
   "source": [
    "df.groupby(['decade', 'provider'])['id'].agg('count').unstack()\\\n",
    "    .plot.bar(title='Documents by decade', figsize=(20, 5), fontsize=12, stacked=True); ##There is a weird bug where this cell needs to be run twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNp2wN8I6oJt"
   },
   "source": [
    "And do the same for the total number of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uifT8Ocy6oJu"
   },
   "outputs": [],
   "source": [
    "df.groupby(['decade', 'provider'])['pageCount'].agg('sum').unstack()\\\n",
    "    .plot.bar(title='Pages by decade', figsize=(20, 5), fontsize=12, stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2-metadata.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
