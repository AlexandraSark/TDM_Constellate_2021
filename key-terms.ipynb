{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDM Key Terms and Concepts\n",
    "\n",
    "## Artificial Intelligence <a id=\"artificial-intelligence\"></a>\n",
    "The science of making intelligent machines, especially machines that react to input data in a way similar to a human being. Historically, artificial intelligence has tended to rely on simple if-then statements (e.g. if the user mentions their mother, ask how she is doing), but recent advancements in artificial intelligence have focused on [machine learning](#machine-learning): the ability of machines to rewrite their own algorithms to improve their accuracy.\n",
    "## Bag of Words (Model) <a id =\"bag-of-words\"></a>\n",
    "A model of texts that counts individual words without regard to grammatical location or phrases. Just as the letters of a Scrabble game are tossed into a bag without order, a \"bag of words\" model gathers all the words of a text into a \"bag\" with no regard to where a particular word occurs within the document. \n",
    "## Bigram <a id=\"bigram\"></a>\n",
    "An [n-gram](#n-gram) with a length of two. For example, \"chicken stock\" is a word bigram.\n",
    "## Bayesian Classification\n",
    "A classification method based on [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) that describes the probability of an event based on available prior knowledge. For example, given a dataset of the historical weather conditions (temperature, humidity, windspeed) from December 25th for every year over the last century, will it snow on December 25th, 2027?\n",
    "## Cleaning (Data)\n",
    "\n",
    "## Clustering\n",
    "## Collocation\n",
    "\n",
    "## Concordance\n",
    "## Content Words\n",
    "As opposed to [function words](#function-words) (e.g. articles, pronouns, conjuctions), content words (e.g. nouns, verbs, and adjectives) carry greater lexical meaning. Word frequency analysis typically attempts to filter out function words, in order to make content words more prominent. This filtering is accomplished with a [stop words](#stop-words) list.\n",
    "## Corpus <a id=\"corpus\"></a>\n",
    "A large (and often structured) collection of texts used for analysis. For example, all of the plays written by Shakespeare. A simple example might be a set of plain text files in a folder on your computer. A more complicated example may use XML, or another form of markup, to allow for deeper analysis. The plural form is corpora.\n",
    "\n",
    "See also [TEI XML](#tei-xml). \n",
    "## CSV (file) <a id=\"csv-file\"></a>\n",
    "A .csv file, or Comma-Separated Value file, is a simple format for storing structured data where each entry in the file is separated by a comma. Similarly, a [TSV file](#tsv-file) uses tabs to separate individual data entries. \n",
    "## Dataset\n",
    "A collection of information, usually computer files, used for statistical analysis. Most datasets are digital text (either numbers, words, or both), but they can also be other formats such as image, audio, and/or video content. Datasets are usually referred to as structured, semi-structured, or unstructured.\n",
    "Structured data fits into a predetermined format and can usually be represented by a table, spreadsheet, or relational database. \n",
    "Unstructured data is more freeform. For example, longform texts, audio, or video content are unstructured. \n",
    "Semi-structured data uses tags or elements to mark out structures within an unstructured data set. Email files, for example, have both structured aspects (Sender, Subject, etc.), but the body of an email is usually unstructured.\n",
    "## Discipline\n",
    "An academic field or body of knowledge taught and studied within colleges or universities. Generally academic disciplines are divided into three large groups: \n",
    "* The Humanities include disciplines like English, History, Law\n",
    "* The Sciences include disciplines like Physics, Biology, Mathematics\n",
    "* The Social Sciences include include disciplines like Anthropology, Economics, and Sociology\n",
    "\n",
    "Academic disciplines as divisions are matters of convenience for organizing departments, but many, if not most, professors research in two or more disciplines at a time. \n",
    "## Environment\n",
    "## Extracted Features\n",
    "## Function Words <a id=\"function-words\"></a>\n",
    "The words in a sentence that have little lexical meaning and express grammatical relationships. Function words include articles, pronouns, and conjunctions. When using a [word frequency](#word-frequency) approach, function words are often filtered out in favor of content words using a [stopwords](#stop-words) list. \n",
    "## Gensim\n",
    "## Google Colab <a id=\"google-colab\"></a>\n",
    "## HathiTrust\n",
    "## HathiTrust Research Center (HTRC)\n",
    "## JSTOR\n",
    "## JupyterHub <a id=\"jupyterhub\"></a>\n",
    "A multi-user version of [The Jupyter Notebook](#the-jupyter-notebook), ideal for teaching environments.\n",
    "## JupyterLab <a id=\"jupyterlab\"></a>\n",
    "The newest software from [Project Jupyter](#project-jupyter), intended to replace [The Jupyter Notebook](#the-jupyter-notebook), for executing and editing [Jupyter notebook](#jupyter-notebook) files.\n",
    "## Jupyter Notebook, The (software) <a id=\"the-jupyter-notebook\"></a>\n",
    "A single-user web application for executing and editing [Jupyter notebook files](#jupyter-notebook). Will be replaced by [JupyterLab](#jupyterlab).\n",
    "## Jupyter notebook (file) <a id=\"jupyter-notebook\"></a>\n",
    "A file with extension .ipynb that contains computer code (e.g. [Python](#python) or R) alongside other explanatory media (text, images, video). \n",
    "## Jupyter Server <a id=\"jupyter-serve\"></a>\n",
    "A server with the appropriate software environment (e.g. [JupyterHub](#jupyterhub), [JupyterLab](#jupyterlab), [Google Colab](#google-colab)) for running and editing [Jupyter notebooks](#jupyter-notebook).\n",
    "## Keyword Extraction\n",
    "## Latent Dirichlet Allocation (LDA)\n",
    "## Lemmatization <a id=\"lemmatization\"></a>\n",
    "## Library (in Python)\n",
    "A collections of methods and functions for achieving certain tasks (e.g. image manipulation, web scraping. This saves time since the code can be added quickly and all at once around a specific group of tasks. The [Natural Language Toolkit (NLTK)](#nltk) is a common library used in [natural language processing](#nlp).\n",
    "## Machine Learning <a id=\"machine-learning\"></a>\n",
    "A subset of [artificial intelligence](#artificial-intelligence) that focuses on a machine algorithms that improve accuracy when exposed to additional data without being explicitly reprogrammed by a human.\n",
    "## N-gram <a id =\"n-gram\"></a>\n",
    "A sequence of n items from a given sample of text or speech. Most often, this refers to a sequence of words, but it can also be used to analyze text at the level of syllables, letters, or phonemes. N-grams are often described by their length. For example, word n-grams might include:\n",
    "* stock (a 1-gram, or unigram)\n",
    "* chicken stock (a 2-gram, or [bigram](#bigram))\n",
    "* homemade chicken stock (a 3-gram, or [trigram](#trigram))\n",
    "A text analysis approach that looks only at unigrams at the word level will not be able to differentiate between the \"stock\" in \"stock market\" and \"chicken stock.\"\n",
    "\n",
    "One of the most popular examples of text analysis with n-grams is the [Google N-Gram Viewer](https://books.google.com/ngrams).\n",
    "\n",
    "See also [Natural Language Processing](#nlp). \n",
    "## Named Entity Recognition (NER)\n",
    "## Natural Language Processing (NLP) <a id=\"nlp\"></a>\n",
    "## Natural Language Toolkit (NLTK) <a id=\"nltk\"></a>\n",
    "A suite of libraries and programs for [Natural Language Processing](#nlp) written in [python](#python). NLTK includes libraries for tokening, collocation, n-grams, Part of Speech (POS) Tagging, and Named Entity Recognition (NER).\n",
    "\n",
    "See the [project documentation](https://www.nltk.org/) and book [Natural Language Processing with Python](http://www.nltk.org/book/).\n",
    "## Neural Net\n",
    "## Optical Character Recognition (OCR)\n",
    "## Package\n",
    "## Part of Speech (POS) Tagging <a id=\"pos-tagging\"></a>\n",
    "## Plain text\n",
    "## Portico\n",
    "## Parts of Speech (POS) Tagging <a id=\"pos-tagging\"></a>\n",
    "## Primary Source\n",
    "## Project Jupyter <a id=\"project-jupyter\"></a>\n",
    "A non-profit that develops open-source software, open standards, and services across many programming languages. They are most well-known for software such as [The Jupyter Notebook](#the-jupyter-notebook), [JupyterLab](#jupyterlab), and [JupyterHub](#jupyterhub). All three of these programs are used to create, edit, and share programming notebooks, known as [Jupyter notebooks](#jupyter-notebook).\n",
    "## Python (Programming Language) <a id=\"python\"></a>\n",
    "\n",
    "## R (Programming Language) <a id=\"r\"></a>\n",
    "## Secondary Source\n",
    "## Sentiment Analsis\n",
    "## Stop Words (List) <a id=\"stop-words\"></a>\n",
    "A stop words list is a set of words or phrases that are ignored in [word frequency](#word-frequency) analysis. It is common for a researcher who is interested in prominent nouns and verbs to remove [function words](#function-words) (e.g. the, and, I, to, of, a). A stop word list may also include other common words, such as character ids which are usually the most common words in a play text.\n",
    "## Tag Cloud (or Word Cloud)<a id =\"tag-cloud\"></a>\n",
    "A tag cloud is a visualization of the relative word frequencies in a [corpus](#corpus). The relative size of each word in a tag cloud depends on its frequency within a text. Larger words occur more frequently.\n",
    "\n",
    "![Tag Cloud of The Narrative of the Life of Frederick Douglass\n",
    "       An American Slave](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tagCloudDouglass.png)\n",
    "**A Tag Cloud of *The Narrative of the Life of Frederick Douglass\n",
    "       An American Slave* generated using Voyant.**\n",
    "## TEI XML <a id =\"tei-xml\"></a>\n",
    "A form of [XML Markup](#xml), or tagging, created by the [Text Encoding Initiative](https://tei-c.org/) to describe digital documents. This markup can help computers recognize particular aspects of the text. Text analysis often requires explicit marking, even for textual aspects that a human reader can easily pick out:\n",
    "* Title\n",
    "* Author Name\n",
    "* Name of the speaker in a play\n",
    "* A paragraph\n",
    "* The speaker in a play\n",
    "* Stage directions\n",
    "* A stanza\n",
    "\n",
    "See also [Parts of Speech Tagging](#pos-tagging), [Lemmatization](#lemmatization), [Tokenization](#tokenization).\n",
    "## Term Frequency\n",
    "## Term Frequency-Inverse Document Frequency (TFIDF)\n",
    "## Text Extraction\n",
    "## Token\n",
    "## Tokenization <a id=\"tokenization\"></a>\n",
    "## Topic Modeling (or Topic Analysis)\n",
    "## Tree Map\n",
    "## Trigram <a id=\"trigram\"></a>\n",
    "An [n-gram](#n-gram) with a length of three. For example, \"homemade chicken stock\" is a word trigram.\n",
    "## TSV (file) <a id=\"tsv-file\"></a>\n",
    "A .tsv file, or Tab-Separated Value file, is a simple format for storing structured data where each entry in the file is separated by a tab. Similarly, a [CSV file](#csv-file) uses commas to separate individual data entries.\n",
    "## Unigram\n",
    "## Voyant\n",
    "## Word2vec\n",
    "## Word Cloud<a id=\"word-cloud\"></a>\n",
    "See [Tag Cloud](#tag-cloud).\n",
    "## Word Embedding\n",
    "## Word Frequency <a id=\"#word-frequency\"></a>\n",
    "A text analysis method that counts the number of occurences of individual words within a particular text. Word frequency uses a [bag of words](#bag-of-words) model where the order of words is not significant. Just as the letters of a Scrabble game are tossed into a bag without order, word frequency merely records the number of occurences with no regard to where a particular word occurs within a document. \n",
    "\n",
    "An alternative to this approach is using [n-grams](#n-gram) which can capture phrases in addition to individual words.\n",
    "\n",
    "Read more about [Word Frequency](./0-why-text-mining.ipynb#wf-method). \n",
    "## XML <a id=\"xml\"></a>\n",
    "Short for (eXtensible markup language), XML uses tags to identify parts of a document for a machine to understand. Like HTML, these tags have an opening tag (e.g. <l>) and a closing tag marked by a forward slash (e.g. </l>). Unlike HTML, these tags can be freely created according to whatever standard the creator needs. One prominent example is the [Text Encoding Initiative](https://tei-c.org/). The example below uses [TEI-XML](#tei-xml) to describe Shakespeare's Sonnet 130 by labeling lines, quatrains, and the final couplet. This kind of markup enables computers to do complex analysis quickly such as comparing every couplet, quatrain, or line in Shakespeare's sonnets.\n",
    "```\n",
    "<text>\n",
    " <body>\n",
    "  <lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>My Mistres eyes are nothing like the Sunne,</l>\n",
    "    <l>Currall is farre more red, then her lips red</l>\n",
    "    <l>If snow be white, why then her brests are dun:</l>\n",
    "    <l>If haires be wiers, black wiers grown on her head:</l>\n",
    "   </lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>I have seene Roses damaskt, red and white,</l>\n",
    "    <l>But no such Roses see I in her cheekes,</l>\n",
    "    <l>And in some perfumes is there more delight,</l>\n",
    "    <l>Then in the breath that from my Mistres reekes.</l>\n",
    "   </lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>I love to heare her speake, yet well I know,</l>\n",
    "    <l>That Musicke hath a farre more pleasing sound:</l>\n",
    "    <l>I graunt I never saw a goddesse goe,</l>\n",
    "    <l>My Mistres when shee walkes treads on the ground.</l>\n",
    "   </lg>\n",
    "  </lg>\n",
    "  <lg type=\"couplet\">\n",
    "   <l>And yet by heaven I think my love as rare,</l>\n",
    "   <l>As any she beli'd with false compare.</l>\n",
    "  </lg>\n",
    " </body>\n",
    "</text>\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
