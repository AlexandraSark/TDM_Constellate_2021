{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZtnwJbt6oJT"
   },
   "source": [
    "Created by [Nathan Kelber](http://nkelber.com) and Ted Lawless for [JSTOR Labs](https://labs.jstor.org/) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "**For questions/comments/improvements, email nathan.kelber@ithaka.org.**<br />\n",
    "![CC BY License Logo](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png)\n",
    "____\n",
    "\n",
    "# Exploring Metadata\n",
    "\n",
    "**Description of methods in this notebook:**\n",
    "This [notebook](https://docs.tdm-pilot.org/key-terms/#jupyter-notebook) shows how to explore the [metadata](https://docs.tdm-pilot.org/key-terms/#metadata) of your [JSTOR](https://docs.tdm-pilot.org/key-terms/#jstor) and/or [Portico](https://docs.tdm-pilot.org/key-terms/#portico) [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) using [Python](https://docs.tdm-pilot.org/key-terms/#python). The following processes are described:\n",
    "\n",
    "* Automatically importing your [JSTOR](https://docs.tdm-pilot.org/key-terms/#jstor) and/or [Portico](https://docs.tdm-pilot.org/key-terms/#portico) [dataset](https://docs.tdm-pilot.org/key-terms/#dataset)\n",
    "* Converting your [JSTOR](https://docs.tdm-pilot.org/key-terms/#jstor) and/or [Portico](https://docs.tdm-pilot.org/key-terms/#portico) [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) into a Python list\n",
    "* Using the `.get` method to retrieve bibliographic metadata\n",
    "* Checking if an item is in your [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) against the dataset metadata\n",
    "* Turning your [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) into a [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) dataframe\n",
    "* Filtering out [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) materials like journal front matter, back matter, notes, etc.\n",
    "* Visualizing the contents of your [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) dataframe by decade\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Purpose:** Learning (Optimized for explanation over code)\n",
    "\n",
    "**Knowledge Required:** \n",
    "* [Python Basics I](./0-python-basics-1.ipynb)\n",
    "* [Python Basics II](./0-python-basics-2.ipynb)\n",
    "* [Python Basics III](./0-python-basics-3.ipynb)\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "\n",
    "* Read [\"What is a JSTOR/Portico dataset (format and structure\"](https://docs.tdm-pilot.org/what-format-are-jstor-portico-datasets/)\n",
    "* A familiarity with [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) is helpful but not required.\n",
    "\n",
    "**Completion time:** 45 minutes\n",
    "\n",
    "**Data Format:** [JSTOR](https://docs.tdm-pilot.org/key-terms/#jstor)/[Portico](https://docs.tdm-pilot.org/key-terms/#portico) [JSON Lines (.jsonl)](https://docs.tdm-pilot.org/key-terms/#jsonl)\n",
    "\n",
    "**Libraries Used:**\n",
    "* [json](https://docs.tdm-pilot.org/key-terms/#json-python-library) to convert our dataset from json lines format to a Python list\n",
    "* [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) to help visualize the metadata\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import your dataset\n",
    "\n",
    "We'll use the `tdm_client` library to automatically upload your dataset. We import the `Dataset` module from the `tdm_client` library. The tdm_client library contains functions for connecting to the JSTOR server containing the [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) [dataset](https://docs.tdm-pilot.org/key-terms/#dataset). To analyze your dataset, use the [dataset ID](https://docs.tdm-pilot.org/key-terms//#dataset-ID) provided when you created your [dataset](https://docs.tdm-pilot.org/key-terms//#dataset). A copy of your [dataset ID](https://docs.tdm-pilot.org/key-terms//#dataset-ID) was sent to your email when you created your [corpus](https://docs.tdm-pilot.org/key-terms/#corpus). It should look like a long series of characters surrounded by dashes. If you haven't created a dataset, feel free to use a sample dataset. Here's a [list by discipline](https://docs.tdm-pilot.org/sample-datasets/). Advanced users can also [upload a dataset from their local machine](https://docs.tdm-pilot.org/uploading-a-dataset/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing your dataset with a dataset ID\n",
    "import tdm_client\n",
    "#Load the sample dataset, the full run of Shakespeare Quarterly from 1950-2013.\n",
    "tdm_client.get_dataset(\"7e41317e-740f-e86a-4729-20dab492e925\", \"sampleJournalAnalysis\") #Insert your dataset ID on this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin working with our [dataset](https://docs.tdm-pilot.org/key-terms/#dataset), we need to convert the [JSON lines](https://docs.tdm-pilot.org/key-terms/#jsonl) file format into [Python](https://docs.tdm-pilot.org/key-terms/#python) so we can work with it. Remember that each line of our [JSON lines](https://docs.tdm-pilot.org/key-terms/#jsonl) file represents a single text, whether that is a journal article, book, or something else. We will create a [Python](https://docs.tdm-pilot.org/key-terms/#python) list that contains every document. Within each list item for each document, we will use a [Python dictionary](https://docs.tdm-pilot.org/key-terms/#python-dictionary) of [key/value pairs](https://docs.tdm-pilot.org/key-terms/#key-value-pair) to store information related to that document. [Read more about the dataset format](https://docs.tdm-pilot.org/what-format-are-jstor-portico-datasets/).\n",
    "\n",
    "Essentially we will have a [list](https://docs.tdm-pilot.org/key-terms/#python-list) of documents numbered, from zero to the last document. Each [list](https://docs.tdm-pilot.org/key-terms/#python-list) item then will be composed of a [dictionary](https://docs.tdm-pilot.org/key-terms/#python-dictionary) of [key/value pairs](https://docs.tdm-pilot.org/key-terms/#key-value-pair) that allows us to retrieve information from that particular document by number. The structure will look something like this:\n",
    "\n",
    "![Structure of the corpus, a list of dictionaries](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CorpusView.png)\n",
    "\n",
    "For each item in our list we will be able to use [key/value pairs](https://docs.tdm-pilot.org/key-terms/#key-value-pair) to get a **value** if we supply a **key**. We will call our [Python list](https://docs.tdm-pilot.org/key-terms/#python-list) variable `all_documents` since it will contain all of the documents in our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tdm_client uses a default `file_name` of `sampleJournalAnalysis.jsonl`.\n",
    "# Unless you have uploaded your own dataset, this code cell requires no modification before running.\n",
    "file_name = 'sampleJournalAnalysis.jsonl' \n",
    "\n",
    "# Import the json module\n",
    "import json\n",
    "# Create an empty new list variable named `all_documents`\n",
    "all_documents = [] \n",
    "# Temporarily open the file `filename` in the datasets/ folder\n",
    "with open('./datasets/' + file_name) as dataset_file: \n",
    "    #for each line in the dataset file\n",
    "    for line in dataset_file: \n",
    "        # Read each line into a Python dictionary.\n",
    "        # Create a variable document that contains the line using json.loads to convert the json key/value pairs to a python dictionary\n",
    "        document = json.loads(line) \n",
    "        # Append a new list item to `all_documents` containing the dictionary we created.\n",
    "        all_documents.append(document) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of our documents have been converted from our original [JSON lines](https://docs.tdm-pilot.org/key-terms/#jsonl) file format (.jsonl) into a [python List](https://docs.tdm-pilot.org/key-terms/#python-list) variable named `all_documents`. Let's see what we can discover about our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) with a few simple methods.\n",
    "\n",
    "First, we can determine how many texts are in our [dataset](https://docs.tdm-pilot.org/key-terms/#dataset) by using the `len()` function to get the size of `all_documents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploring the Metadata of a Single Article\n",
    "\n",
    "We can also choose a single document and get [bibliographic metadata](https://docs.tdm-pilot.org/key-terms/#bibliographic-metadata) for that item. First we select a document from our list ```all_documents```. (In computer code, 0 is the first item, 1 is the second item, 2 is the third item, etc.) If we wanted to select the first item, we could use the `.get` method to retrieve the title for the item in our [list](https://docs.tdm-pilot.org/key-terms/#python-list) by writing `all_documents[0]`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new dictionary variable `chosenDocument` that is equal to a single item in our `all_documents` list\n",
    "chosen_document = all_documents[0] # Select the first document in our list\n",
    "chosen_document.get('title') #get the corresponding value for the key 'title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `.get` method to discover additional [bibliographic metadata](https://docs.tdm-pilot.org/key-terms/#bibliographic-metadata). Here are the most significant [bibliographic metadata](https://docs.tdm-pilot.org/key-terms/#bibliographic-metadata) items found with a [JSTOR](https://docs.tdm-pilot.org/key-terms/#jstor) item:\n",
    "* `title` returns the title\n",
    "* `creators` returns the authors in a Python list\n",
    "* `isPartOf` returns the journal title\n",
    "* `datePublished` returns the publication date\n",
    "* `id` returns the stable URL for a JSTOR item\n",
    "* `identifier` returns a Python list of dictionaries containing the ISSN #, OCLC #, and DOI #. \n",
    "* `volumeNumber` returns the journal volume number\n",
    "* `pageCount` returns the number of pages in the print article\n",
    "* `pagination` returns the page number range of the print article\n",
    "* `pageStart` returns the first print page\n",
    "* `pageEnd` returns the last print page\n",
    "* `wordCount` returns the number of words in the article\n",
    "* `docType` returns the type of document, usually `article` for journal article\n",
    "* `url` returns the stable url for the document\n",
    "* `provider` returns the source of the data, for JSTOR articles usually `jstor`\n",
    "* `language` returns the language the article is written in\n",
    "\n",
    "Let's try all these on our `chosenDocument`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Title: \" + chosen_document.get('title'))\n",
    "print(\"Authors: \", end='')\n",
    "print(chosen_document.get('creator'))\n",
    "print(\"Journal: \" + chosen_document.get('isPartOf'))\n",
    "print(\"Publication Date: \" + chosen_document.get('datePublished'))\n",
    "#print(\"Publisher: \" + chosen_document.get('publisher'))\n",
    "print(\"ID: \" + chosen_document.get('id'))\n",
    "print(\"ISSN, OCLC, DOI: \", end='')\n",
    "print(chosen_document.get('identifier'))\n",
    "#print(\"Volume Number: \" + chosen_document.get('volumeNumber'))\n",
    "print(\"Number of Pages: \" + str(chosen_document.get('pageCount')))\n",
    "print(\"Print Pagination: \" + str(chosen_document.get('pagination')))\n",
    "print(\"First Page: \" + str(chosen_document.get('pageStart')))\n",
    "print(\"Last Page: \" + str(chosen_document.get('pageEnd')))\n",
    "print(\"Number of words: \" + str(chosen_document.get('wordCount')))\n",
    "print(\"Document Type: \" + chosen_document.get('docType'))\n",
    "print(\"URL: \" + chosen_document.get('url'))\n",
    "print(\"Provider: \" + chosen_document.get('provider'))\n",
    "print(\"Language: \" + str(chosen_document.get('language')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see every [Python dictionary](https://docs.tdm-pilot.org/key-terms/#python-dictionary) **key** in the [metadata](https://docs.tdm-pilot.org/key-terms/#metadata) by using the `.keys` method. We could use this in conjunction with the `print()` function, but we will use the `list()` function here to make it a little neater for reading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(chosen_document.keys())# Uncomment the # in front of print to run this line of code\n",
    "list(chosen_document.keys()) # Create a list of every Python dictionary key within `chosen_document`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could also list all the [Python dictionary](https://docs.tdm-pilot.org/key-terms/#python-dictionary) **values**, but the output will be quite long since it includes the word counts for every word that is in the article. (In fact, it includes the count for every unique [string](https://docs.tdm-pilot.org/key-terms/#string) in the article. We'll address the distinction in the [word frequencies](https://docs.tdm-pilot.org/key-terms/#word-frequency) [notebooks](https://docs.tdm-pilot.org/key-terms/#jupyter-notebook).) The word counts are found within `unigramCount` which we'll address in the word frequencies notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the # in the next line to display all values in chosen_document\n",
    "list(chosen_document.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checking if a particular document is in the corpus\n",
    "\n",
    "Let's return to our larger [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) `all_documents` to do some exploratory analysis. What if we wanted to check if a particular item was in the [corpus](https://docs.tdm-pilot.org/key-terms/#corpus)?\n",
    "\n",
    "Assuming the item is from JSTOR, we could search out any journal article on jstor.org. The article description page will feature a stable url.\n",
    "\n",
    "![A JSTOR description page](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/jstorDescription.png)\n",
    "\n",
    "We already saw above that the stable URL is stored in both the `id` and `url` dictionaries, so we can check our whole [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) for a particular JSTOR article if we know the stable URL. (If we are looking at a Portico item, they will have an `id` that starts with `ark://` and `url` that lists a `doi`.) From the image above, we can see the article in question has a stable URL of: https://www.jstor.org/stable/2871420\n",
    "\n",
    "We can check whether the item above is in `all_documents` with the `in` or `not in` operators. First though, we need a list of all of the URLs in our corpus. We'll create a variable `list_of_urls` to hold all these values. Then we can check to see if our stable URL (http://www.jstor.org/stable/2871420) is in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a blank list that will contain all of the urls in our dataset\n",
    "list_of_urls = [] \n",
    "# For every document in our dataset\n",
    "for document in all_documents:\n",
    "    # Create a url_value variable to hold the URL for that document\n",
    "    url_value = document.get('url') \n",
    "    # Append or add that URL to our Python list `list_of_urls`\n",
    "    list_of_urls.append(url_value)\n",
    "# Show the first five items in our list of urls\n",
    "list(list_of_urls[0:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a [list](https://docs.tdm-pilot.org/key-terms/#python-list) of all the URLs in our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) in the `list_of_urls` variable, let's use the `in` operator to discover whether our text is in the [corpus](https://docs.tdm-pilot.org/key-terms/#corpus). If the article is in our [dataset](https://docs.tdm-pilot.org/key-terms/#dataset), we will receive `true`. If the article is not our [dataset](https://docs.tdm-pilot.org/key-terms/#dataset), we will receive `false`.\n",
    "\n",
    "*Note that the stable URL from jstor.org uses a secure address starting with \"https://\". Our dictionary values, however, use a standard address beginning with \"http://\".\n",
    "* http**s**://\n",
    "* http://\n",
    "\n",
    "You'll need to remove the \"s\" to run this test since our `list_of_urls` are not secure addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'http://www.jstor.org/stable/24778550' in list_of_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toqiQRaZ6oJd"
   },
   "source": [
    "Now we have a good idea of what [metadata](https://docs.tdm-pilot.org/key-terms/#metadata) is in our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) and how we might retrieve it. We were able to use the `in` operator above to check if a particular article was in the [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) using the URL. Of course, we could also check to see if a particular journal, author, publisher, or DOI # was in our corpus using a similar method. \n",
    "\n",
    "We'll finish this [notebook](https://docs.tdm-pilot.org/key-terms/#jupyter-notebook) by taking a big picture look at the [corpus](https://docs.tdm-pilot.org/key-terms/#corpus). What largescale patterns exist in this [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) over the decades? We'll use [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) to help with our analysis. If you would like to learn more about [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas), we recommend the [Python Pandas tutorial at learndatasci.com](https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/). For now, we will create a couple visualizations for demonstration purposes.\n",
    "\n",
    "---\n",
    "## Explore Corpus Metadata with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9IRRS466oJU"
   },
   "outputs": [],
   "source": [
    "# Imports pandas and allows us to call it with the phrase pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas), we need to import it first. The `as pd` lets us use the shorthand `pd` when we want to call [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) instead writing out the entire word `pandas`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHkQ1o7P6oJh"
   },
   "source": [
    "Now we can turn our [Python list](https://docs.tdm-pilot.org/key-terms/#python-list) `all_documents` into a [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe). This will enable us to manipulate and view our data as a table or a graph. We will call our [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe) `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWaiiLtC6oJi"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIDbi3SD6oJj"
   },
   "source": [
    "Let's see what our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) looks like in table form. We can use the `.head()` method to show us the first five rows of our data as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIJ8H0pT6oJk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOkMFJ246oJl"
   },
   "source": [
    "Now we can see the first part of all the [metadata](https://docs.tdm-pilot.org/key-terms/#metadata) we have been discussing in table form. Much clearer! There's a lot of [metadata](https://docs.tdm-pilot.org/key-terms/#metadata) here so you may need to scroll right to see all the columns. Long items in this view are abbreviated with `...` to signify that they continue past what is shown. To see all the columns, we can set an option in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show all columns\n",
    "pd.set_option(\"max_columns\", None) # Show all columns\n",
    "# We could do the same with \"max_rows\" but the length would be too long to effectively scroll through.\n",
    "\n",
    "df.head() # Show the first five rows of our DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe) to learn a little more about our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus). First, we may not be interested in every column so let's simplify our dataframe by dropping columns that may not be useful to us. We'll drop:\n",
    "\n",
    "* identifier\n",
    "* outputFormat\n",
    "* sourceCategory\n",
    "* pageEnd\n",
    "* pageStart\n",
    "* pagination\n",
    "* datePublished\n",
    "\n",
    "Add any others you might like to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['identifier', 'outputFormat', 'sourceCategory', 'pageEnd', 'pageStart', 'pagination', 'datePublished', 'language'], axis=1) # Drop each of these named columns\n",
    "df #display df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also drop any rows where the creator/author is blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['creator']) #drop each row that has no value under 'creators'\n",
    "df #display df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally clean up some of the data based on parameters relevant to our goals and dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the dataset by removing entries. Customize these choices to your goals and dataset.\n",
    "\n",
    "# Examples for cleaning up the data based on the values found under 'title'\n",
    "\n",
    "df = df[df.title != 'Review Article'] # Remove articles with title \"Review Article\"\n",
    "df = df[df.title != 'Front Matter'] # Remove articles with title \"Front Matter\"\n",
    "df = df[df.title != 'Back Matter'] # Remove articles with title \"Back Matter\"\n",
    "\n",
    "# Examples for cleaning up the data based on values found under 'wordCount'\n",
    "\n",
    "df = df[df.wordCount > 3000] # Remove articles with fewer than 3000 words, adjust or remove\n",
    "df #display df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sort Articles by Decade with Pandas\n",
    "\n",
    "Notice above there is column labeled `publicationYear`. Let's figure out the full year range of our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus). We can do this by using the `.min` and `.max` methods. We'll create a variable to store each and then print them out.\n",
    "\n",
    "We can find the year range in our [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe) by finding the minimum and maximum of `publicationYear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkhgmqPo6oJm"
   },
   "outputs": [],
   "source": [
    "min_year = df['publicationYear'].min() #create variable `minYear` that is the minimum value from `publicationYear`\n",
    "max_year = df['publicationYear'].max() #create variable `maxYear` that is the maximum value from `publicationYear`\n",
    "\n",
    "print(str(min_year) + ' to ' + str(max_year)) #print a string showing \"minYear to maxYear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtjvEi9n6oJn"
   },
   "source": [
    "Now we know the full year range of our [dataset](https://docs.tdm-pilot.org/key-terms/#dataset). Let's see if we can identify any trends across the decades.\n",
    "\n",
    "Since `decade` isn't a column in our [Pandas](https://docs.tdm-pilot.org/key-terms/#pandas) [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe), we'll need to create it. First though, we'll need to consider how to turn a date into a decade. Let's try an example.  To translate a year (1925) to a decade (1920), we need to subtract the final digit so it becomes a zero. Basically, we need a way to discover the final digit in each decade and then subtract it so the final digit of our date becomes a zero. Something like:\n",
    "\n",
    "`1925 - 5 = 0`\n",
    "\n",
    "We can find the value for the final digit in any particular case by using [modulo](https://docs.tdm-pilot.org/key-terms/#modulo) (which provides the remainder of a division). If we use `% 10` on a date, it should give us a remainder that is the ones digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the remainder of 1925 divided by 10?\n",
    "1925 % 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will give us our ones digit. Now we subtract this calculation from our original date. The result gives us the decade number we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1925 - (1925 % 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can translate this example to the whole [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe) using the following code. We'll create a new function `add_decade` that takes a `value` from the `publicationYear` column and translates it into a decade column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWoq2gMt6oJn"
   },
   "outputs": [],
   "source": [
    "# Create a function `add_decade` that takes an argument `value`\n",
    "def add_decade(value): \n",
    "    # Create a variable `yr` that turns value from a string into an integer\n",
    "    yr = int(value) \n",
    "    # Create a variable `decade` that subtracts the ones digit by using the modulo (%) operator\n",
    "    decade = yr - ( yr % 10 ) \n",
    "    # Return the variable `decade` for the function `add_decade`\n",
    "    return decade\n",
    "\n",
    "df['decade'] = df['publicationYear'].apply(add_decade) \n",
    "# create a new column `decade` in our dataframe that is equal to \n",
    "# the column `publicationYear` after applying \n",
    "# the add_decade function we created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H79W5vIw6oJp"
   },
   "source": [
    "To see the new decade column we created in our data, let's use the `df.head()` method again to see how it changed the first 5 rows of the [dataframe](https://docs.tdm-pilot.org/key-terms/#pandas-dataframe). To see the decade column, you will need to scroll all the way to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKCjvDna6oJq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lwdgRAf6oJr"
   },
   "source": [
    "___\n",
    "## Plot the Data by Decade\n",
    "\n",
    "For a final demonstration, we'll create two graphs of our [corpus](https://docs.tdm-pilot.org/key-terms/#corpus) using our new decade column. Let's look at the number of documents by decade first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upxLwnZr6oJs"
   },
   "outputs": [],
   "source": [
    "# Group the data by decade and the aggregated number of ids into a bar chart\n",
    "# There is a weird bug where this cell needs to be run twice to be shown\n",
    "\n",
    "df.groupby(['decade'])['id'].agg('count').plot.bar(title='Documents by decade', figsize=(20, 5), fontsize=12); \n",
    "\n",
    "# Read more about Pandas dataframe plotting here: \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNp2wN8I6oJt"
   },
   "source": [
    "And now let's look at the total page numbers by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uifT8Ocy6oJu"
   },
   "outputs": [],
   "source": [
    "# Group the data by decade and aggregated sum of the page counts into a bar chart\n",
    "\n",
    "df.groupby(['decade'])['pageCount'].agg('sum').plot.bar(title='Pages by decade', figsize=(20, 5), fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Start Next Lesson: [Exploring Word Frequencies](./1-word-frequencies.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2-metadata.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
